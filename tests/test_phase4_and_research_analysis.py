#!/usr/bin/env python3
"""Phase 4 Unified System Test & Research Analysis Runner

This script tests the unified GIMAN system and runs comprehensive research analysis
including statistical testing, feature importance, counterfactual generation,
and publication-ready visualizations.

Author: GIMAN Development Team
Date: September 24, 2025
"""

import logging
import sys
import warnings
from pathlib import Path

import numpy as np
import torch

warnings.filterwarnings("ignore")

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("phase4_test_and_analysis.log"),
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger(__name__)


def main():
    """Run Phase 4 unified system test and comprehensive research analysis."""
    logger.info("üöÄ Starting Phase 4 Unified System Test & Research Analysis")

    try:
        # Import necessary modules
        from phase3_1_real_data_integration import RealDataPhase3Integration
        from phase4_unified_giman_system import (
            GIMANResearchAnalyzer,
            UnifiedGIMANSystem,
        )

        # Try to import research analytics (handle missing SHAP/LIME gracefully)
        try:
            from giman_research_analytics import GIMANResearchAnalytics

            research_analytics_available = True
        except ImportError as e:
            logger.warning(
                f"Research analytics not fully available due to missing dependencies: {e}"
            )
            research_analytics_available = False

        # === PHASE 4 SYSTEM SETUP ===
        logger.info("üìä Loading PPMI data...")

        # Setup device first
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"üîß Using device: {device}")

        # Load data using Phase 3.1 integration class
        phase3_integration = RealDataPhase3Integration(device=device)
        prognostic_data = phase3_integration.load_real_ppmi_data()
        phase3_integration.generate_spatiotemporal_embeddings()
        phase3_integration.generate_genomic_embeddings()

        # Get embeddings from the integration class
        spatial_emb = phase3_integration.spatiotemporal_embeddings
        genomic_emb = phase3_integration.genomic_embeddings

        # Check if embeddings were created successfully
        if spatial_emb is None or genomic_emb is None:
            logger.error(
                "Failed to generate embeddings. Using synthetic data for testing."
            )
            # Create synthetic data for testing
            n_patients = 95  # Based on log output
            spatial_emb = np.random.randn(n_patients, 256)
            genomic_emb = np.random.randn(n_patients, 256)

        # Create temporal embeddings from prognostic data
        temporal_emb = np.random.randn(
            spatial_emb.shape[0], 256
        )  # Placeholder for temporal features

        n_patients = spatial_emb.shape[0]
        logger.info(f"‚úÖ Loaded data for {n_patients} patients")

        # Create analyzer and unified system
        analyzer = GIMANResearchAnalyzer(device=device)
        analyzer.spatiotemporal_embeddings = spatial_emb
        analyzer.genomic_embeddings = genomic_emb
        analyzer.temporal_embeddings = temporal_emb

        # Setup unified system
        embed_dim = spatial_emb.shape[1]  # Should be 256

        unified_system = UnifiedGIMANSystem(
            embed_dim=embed_dim, num_heads=4, dropout=0.4
        ).to(device)

        logger.info("‚úÖ Unified system initialized")

        # === PHASE 4 TRAINING ===
        logger.info("üéØ Training Phase 4 Unified System...")

        # Prepare targets (use synthetic data if prognostic_data is None)
        if prognostic_data is None:
            logger.warning(
                "No prognostic data available. Creating synthetic targets for testing."
            )
            n_patients = spatial_emb.shape[0]
            motor_scores = (
                np.random.randn(n_patients) * 2.0
            )  # Synthetic motor progression scores
            cognitive_conversion = np.random.binomial(
                1, 0.3, n_patients
            )  # 30% conversion rate
        else:
            motor_scores = prognostic_data["motor_progression"].values
            cognitive_conversion = prognostic_data["cognitive_conversion"].values

        # Normalize motor scores
        motor_mean = np.mean(motor_scores)
        motor_std = np.std(motor_scores)
        motor_scores_norm = (motor_scores - motor_mean) / motor_std

        # Train/validation/test split (60/20/20)
        n_train = int(0.6 * n_patients)
        n_val = int(0.2 * n_patients)

        indices = np.random.permutation(n_patients)
        train_idx = indices[:n_train]
        val_idx = indices[n_train : n_train + n_val]
        test_idx = indices[n_train + n_val :]

        # Convert to tensors
        spatial_tensor = torch.tensor(spatial_emb, dtype=torch.float32).to(device)
        genomic_tensor = torch.tensor(genomic_emb, dtype=torch.float32).to(device)
        temporal_tensor = torch.tensor(temporal_emb, dtype=torch.float32).to(device)
        motor_tensor = torch.tensor(motor_scores_norm, dtype=torch.float32).to(device)
        cognitive_tensor = torch.tensor(cognitive_conversion, dtype=torch.float32).to(
            device
        )

        # Training setup
        optimizer = torch.optim.AdamW(
            unified_system.parameters(), lr=0.001, weight_decay=0.01
        )
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)

        # Training loop
        best_val_loss = float("inf")
        patience = 20
        patience_counter = 0

        for epoch in range(200):
            unified_system.train()

            # Training step
            optimizer.zero_grad()

            train_outputs = unified_system(
                spatial_tensor[train_idx],
                genomic_tensor[train_idx],
                temporal_tensor[train_idx],
            )

            # Calculate losses
            motor_loss = torch.nn.functional.huber_loss(
                train_outputs["motor_prediction"].squeeze(), motor_tensor[train_idx]
            )

            cognitive_loss = torch.nn.functional.binary_cross_entropy_with_logits(
                train_outputs["cognitive_prediction"].squeeze(),
                cognitive_tensor[train_idx],
            )

            total_loss = motor_loss + cognitive_loss
            total_loss.backward()

            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(unified_system.parameters(), max_norm=1.0)

            optimizer.step()
            scheduler.step()

            # Validation
            if epoch % 10 == 0:
                unified_system.eval()
                with torch.no_grad():
                    val_outputs = unified_system(
                        spatial_tensor[val_idx],
                        genomic_tensor[val_idx],
                        temporal_tensor[val_idx],
                    )

                    val_motor_loss = torch.nn.functional.huber_loss(
                        val_outputs["motor_prediction"].squeeze(), motor_tensor[val_idx]
                    )

                    val_cognitive_loss = (
                        torch.nn.functional.binary_cross_entropy_with_logits(
                            val_outputs["cognitive_prediction"].squeeze(),
                            cognitive_tensor[val_idx],
                        )
                    )

                    val_total_loss = val_motor_loss + val_cognitive_loss

                    logger.info(
                        f"Epoch {epoch:3d}: Train Loss = {total_loss:.4f}, Val Loss = {val_total_loss:.4f}"
                    )

                    # Early stopping
                    if val_total_loss < best_val_loss:
                        best_val_loss = val_total_loss
                        patience_counter = 0
                    else:
                        patience_counter += 1

                    if patience_counter >= patience:
                        logger.info(f"Early stopping at epoch {epoch}")
                        break

        # === PHASE 4 TESTING ===
        logger.info("üß™ Testing Phase 4 Unified System...")

        unified_system.eval()
        with torch.no_grad():
            test_outputs = unified_system(
                spatial_tensor[test_idx],
                genomic_tensor[test_idx],
                temporal_tensor[test_idx],
            )

            motor_pred = test_outputs["motor_prediction"].squeeze().cpu().numpy()
            cognitive_pred = (
                torch.sigmoid(test_outputs["cognitive_prediction"].squeeze())
                .cpu()
                .numpy()
            )

            motor_true = motor_tensor[test_idx].cpu().numpy()
            cognitive_true = cognitive_tensor[test_idx].cpu().numpy()

        # Calculate metrics
        from sklearn.metrics import r2_score, roc_auc_score

        motor_r2 = r2_score(motor_true, motor_pred)
        cognitive_auc = roc_auc_score(cognitive_true, cognitive_pred)

        logger.info("üéØ Phase 4 Results:")
        logger.info(f"   Motor R¬≤: {motor_r2:.4f}")
        logger.info(f"   Cognitive AUC: {cognitive_auc:.4f}")

        # Prepare results for research analysis
        training_results = {
            "test_indices": test_idx,
            "test_metrics": {"motor_r2": motor_r2, "cognitive_auc": cognitive_auc},
            "test_predictions": {
                "motor": motor_pred,
                "motor_true": motor_true,
                "cognitive": cognitive_pred,
                "cognitive_true": cognitive_true,
            },
        }

        # === RESEARCH ANALYSIS ===
        if research_analytics_available:
            logger.info("üî¨ Running comprehensive research analysis...")

            results_dir = Path("results/phase4_research_analysis")
            research_analytics = GIMANResearchAnalytics(
                unified_system=unified_system,
                analyzer=analyzer,
                results_dir=results_dir,
            )

            # Run comprehensive analysis
            publication_analysis = (
                research_analytics.generate_publication_ready_analysis(training_results)
            )

            logger.info("‚úÖ Research analysis completed")
            logger.info(f"üìä Results saved to: {results_dir}")

        else:
            # Create basic analysis without SHAP/LIME
            logger.info(
                "üìä Creating basic analysis (without advanced interpretability)..."
            )

            results_dir = Path("results/phase4_basic_analysis")
            results_dir.mkdir(parents=True, exist_ok=True)

            # Basic statistical analysis
            from scipy.stats import pearsonr

            motor_correlation, motor_p_value = pearsonr(motor_true, motor_pred)

            # Create basic visualization
            import matplotlib.pyplot as plt

            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

            # Motor predictions
            ax1.scatter(motor_true, motor_pred, alpha=0.6)
            ax1.plot(
                [min(motor_true), max(motor_true)],
                [min(motor_true), max(motor_true)],
                "r--",
            )
            ax1.set_xlabel("True Motor Progression")
            ax1.set_ylabel("Predicted Motor Progression")
            ax1.set_title(f"Motor Prediction (R¬≤ = {motor_r2:.4f})")
            ax1.grid(True, alpha=0.3)

            # Cognitive predictions
            from sklearn.metrics import precision_recall_curve

            precision, recall, _ = precision_recall_curve(
                cognitive_true, cognitive_pred
            )

            ax2.plot(recall, precision, linewidth=2)
            ax2.set_xlabel("Recall")
            ax2.set_ylabel("Precision")
            ax2.set_title(f"Cognitive Prediction (AUC = {cognitive_auc:.4f})")
            ax2.grid(True, alpha=0.3)

            # Phase comparison
            phases = [
                "Phase 3.1",
                "Phase 3.2\n(Original)",
                "Phase 3.2\n(Improved)",
                "Phase 4\n(Unified)",
            ]
            motor_r2_values = [-0.6481, -1.4432, -0.0760, motor_r2]
            cognitive_auc_values = [0.4417, 0.5333, 0.7647, cognitive_auc]

            x = np.arange(len(phases))
            width = 0.35

            ax3.bar(x - width / 2, motor_r2_values, width, label="Motor R¬≤", alpha=0.8)
            ax3.bar(
                x + width / 2,
                cognitive_auc_values,
                width,
                label="Cognitive AUC",
                alpha=0.8,
            )
            ax3.set_xlabel("GIMAN Phase")
            ax3.set_ylabel("Performance Score")
            ax3.set_title("Performance Comparison Across Phases")
            ax3.set_xticks(x)
            ax3.set_xticklabels(phases)
            ax3.legend()
            ax3.grid(True, alpha=0.3)

            # Summary statistics
            ax4.axis("off")
            summary_text = f"""
Phase 4 Unified System Results:

Performance Metrics:
‚Ä¢ Motor R¬≤: {motor_r2:.4f}
‚Ä¢ Cognitive AUC: {cognitive_auc:.4f}
‚Ä¢ Motor Correlation: {motor_correlation:.4f} (p={motor_p_value:.4f})

Comparison to Previous Phases:
‚Ä¢ Improvement over Phase 3.1: {motor_r2 - (-0.6481):.4f} Motor R¬≤
‚Ä¢ Improvement over Phase 3.2 Original: {motor_r2 - (-1.4432):.4f} Motor R¬≤
‚Ä¢ Compared to Phase 3.2 Improved: {motor_r2 - (-0.0760):.4f} Motor R¬≤

Clinical Assessment:
‚Ä¢ Motor Prediction: {"Good" if motor_r2 > 0.1 else "Moderate" if motor_r2 > 0.0 else "Limited"}
‚Ä¢ Cognitive Prediction: {"Excellent" if cognitive_auc > 0.8 else "Good" if cognitive_auc > 0.7 else "Moderate"}
‚Ä¢ Overall: {"Ready for pilot studies" if cognitive_auc > 0.75 else "Needs optimization"}
"""

            ax4.text(
                0.05,
                0.95,
                summary_text,
                transform=ax4.transAxes,
                fontsize=11,
                verticalalignment="top",
                fontfamily="monospace",
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.8),
            )

            plt.suptitle(
                "GIMAN Phase 4: Unified System Analysis", fontsize=16, fontweight="bold"
            )
            plt.tight_layout()
            plt.savefig(
                results_dir / "phase4_analysis.png", dpi=300, bbox_inches="tight"
            )
            plt.close()

            logger.info(f"üìä Basic analysis saved to: {results_dir}")

        # === SUMMARY ===
        logger.info("üéâ Phase 4 Test & Analysis Complete!")
        logger.info("üìà Final Performance:")
        logger.info(f"   Motor R¬≤: {motor_r2:.4f}")
        logger.info(f"   Cognitive AUC: {cognitive_auc:.4f}")

        # Compare to all previous phases
        phase_comparison = {
            "Phase 3.1": {"motor_r2": -0.6481, "cognitive_auc": 0.4417},
            "Phase 3.2 (Original)": {"motor_r2": -1.4432, "cognitive_auc": 0.5333},
            "Phase 3.2 (Improved)": {"motor_r2": -0.0760, "cognitive_auc": 0.7647},
            "Phase 4 (Unified)": {"motor_r2": motor_r2, "cognitive_auc": cognitive_auc},
        }

        logger.info("\nüìä Complete Phase Comparison:")
        for phase, metrics in phase_comparison.items():
            logger.info(
                f"   {phase}: Motor R¬≤ = {metrics['motor_r2']:+.4f}, Cognitive AUC = {metrics['cognitive_auc']:.4f}"
            )

        # Determine best performing phase
        best_motor_phase = max(phase_comparison.items(), key=lambda x: x[1]["motor_r2"])
        best_cognitive_phase = max(
            phase_comparison.items(), key=lambda x: x[1]["cognitive_auc"]
        )

        logger.info("\nüèÜ Best Performance:")
        logger.info(
            f"   Motor Prediction: {best_motor_phase[0]} (R¬≤ = {best_motor_phase[1]['motor_r2']:.4f})"
        )
        logger.info(
            f"   Cognitive Prediction: {best_cognitive_phase[0]} (AUC = {best_cognitive_phase[1]['cognitive_auc']:.4f})"
        )

        return training_results

    except Exception as e:
        logger.error(f"‚ùå Error in Phase 4 test: {str(e)}")
        import traceback

        logger.error(traceback.format_exc())
        raise


if __name__ == "__main__":
    results = main()
